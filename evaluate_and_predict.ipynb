{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation and Prediction\n",
    "\n",
    "This notebook evaluates and makes predictions with models we trained.\n",
    "1. CNN\n",
    "2. ArcFace\n",
    "3. tfidf\n",
    "4. ArcFace+tfidf\n",
    "\n",
    "References: https://www.kaggle.com/ragnar123/unsupervised-baseline-arcface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from sklearn import metrics\n",
    "#from tensorflow.keras import backend as K\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV_PATH = '../../data/train.csv'\n",
    "TRAIN_IMG_DIR = '../../data/train_images/'\n",
    "ARCFACE_MODEL_PATH = './trained/arcface_best_epoch_512_42.h5'\n",
    "CNN_MODEL_PATH = './trained/CNN.h5'\n",
    "N_CLASSES = 11014\n",
    "IMAGE_SIZE = [512,512]\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_csv():\n",
    "    '''\n",
    "    Read and prepare the tabular records\n",
    "    '''\n",
    "    train = pd.read_csv(TRAIN_CSV_PATH)\n",
    "    tmp = train.groupby(['label_group'])['posting_id'].unique().to_dict()\n",
    "    train['matches'] = train['label_group'].map(tmp)\n",
    "    train['matches'] = train['matches'].apply(lambda x: ' '.join(x))\n",
    "    img_paths = TRAIN_IMG_DIR + train['image']\n",
    "        \n",
    "    return train, img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(image):\n",
    "    '''\n",
    "    Parse an image\n",
    "    '''\n",
    "    image = tf.io.read_file(image)\n",
    "    image = util.decode_image(image, IMAGE_SIZE)\n",
    "    return image\n",
    "\n",
    "# Function to get our dataset that read images\n",
    "def get_dataset_img(image):\n",
    "    '''\n",
    "    Read and prepare the image dataset\n",
    "    '''\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(image)\n",
    "    dataset = dataset.map(read_image, num_parallel_calls = AUTO)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(which='arcface'):\n",
    "    '''\n",
    "    Load pretrained image models\n",
    "    '''\n",
    "    \n",
    "    assert(which=='arcface' or which=='cnn'), 'which==\\'arcface\\' or \\'cnn\\''\n",
    "    \n",
    "    if which == 'cnn':\n",
    "        print('Reminder: image size = (224,224)')\n",
    "        return tf.keras.models.load_model('./trained/CNN.h5')\n",
    "    \n",
    "    inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3), name = 'inp1')\n",
    "    label = tf.keras.layers.Input(shape = (), name = 'inp2')\n",
    "    x = EfficientNetB3(weights = 'imagenet', include_top = False)(inp)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    margin = util.ArcMarginProduct(\n",
    "        n_classes = N_CLASSES, \n",
    "        s = 30, \n",
    "        m = 0.5, \n",
    "        name='head/arc_margin', \n",
    "        dtype='float32'\n",
    "    )\n",
    "    \n",
    "    x = margin([x, label])\n",
    "\n",
    "    output = tf.keras.layers.Softmax(dtype='float32')(x)\n",
    "    model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n",
    "    model.load_weights(ARCFACE_MODEL_PATH)\n",
    "    model = tf.keras.models.Model(inputs = model.input[0], outputs = model.layers[-4].output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_images(img_paths, model):\n",
    "    image_dataset = get_dataset_img(img_paths)\n",
    "    image_embeddings = model.predict(image_dataset)   \n",
    "    return image_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_titles(df, max_features = 15500):\n",
    "    tfidf = TfidfVectorizer(stop_words = 'english', binary = True, max_features = max_features)\n",
    "    text_embeddings = tfidf.fit_transform(df['title'])\n",
    "    return text_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbor(df, \n",
    "                     embeddings, \n",
    "                     thresholds = np.arange(0.3,0.6,0.01), \n",
    "                     n_neighbors = 50):\n",
    "    '''\n",
    "    1. Performs knn, then find the best threshold\n",
    "    2. Use the best threshold to make predictions\n",
    "    '''\n",
    "\n",
    "    knn = NearestNeighbors(n_neighbors = n_neighbors, metric='cosine')\n",
    "    knn.fit(embeddings)\n",
    "    \n",
    "    distances, indices = knn.kneighbors(embeddings)\n",
    "    \n",
    "    scores = []\n",
    "    for threshold in thresholds:\n",
    "        preds = []\n",
    "        for k in range(embeddings.shape[0]):\n",
    "            index_matches = np.where(distances[k,] < threshold)[0]\n",
    "            id_matches = indices[k,index_matches]\n",
    "            posting_ids = ' '.join(df['posting_id'].iloc[id_matches].values)\n",
    "            preds.append(posting_ids)\n",
    "        df['pred_matches'] = preds\n",
    "        df['f1'] = util.f1_score(df['matches'], df['pred_matches'])\n",
    "        score = df['f1'].mean()\n",
    "        print(f'Threshold:{threshold} - F1: {score}')\n",
    "        scores.append(score)\n",
    "    df_thresholds = pd.DataFrame({'threshold':thresholds,'f1':scores})\n",
    "    best_f1 = df_thresholds.f1.max()\n",
    "    best_threshold = df_thresholds[df_thresholds.f1==best_f1].threshold.min()\n",
    "    print('-'*100)\n",
    "    print(f'The best threshold is {best_threshold} with an f1 of {best_f1}')\n",
    "    \n",
    "    best_preds = []\n",
    "    for k in range(embeddings.shape[0]):\n",
    "        index_matches = np.where(distances[k,] < best_threshold)[0]\n",
    "        id_matches = indices[k,index_matches]\n",
    "        posting_ids = df['posting_id'].iloc[id_matches].values\n",
    "        best_preds.append(posting_ids)\n",
    "    \n",
    "    return df, best_threshold, best_f1, best_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, img_paths = get_dataset_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('arcface')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image embeddings shape is (34250, 1536)\n"
     ]
    }
   ],
   "source": [
    "# 00:06:00\n",
    "image_embeddings = embed_images(img_paths, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold:0.3 - F1: 0.807931808369746\n",
      "Threshold:0.31 - F1: 0.815814757157693\n",
      "Threshold:0.32 - F1: 0.8227750264643898\n",
      "Threshold:0.33 - F1: 0.8296851575414907\n",
      "Threshold:0.34 - F1: 0.836653371502557\n",
      "Threshold:0.35000000000000003 - F1: 0.8435490339690283\n",
      "Threshold:0.36000000000000004 - F1: 0.8497741344366871\n",
      "Threshold:0.37000000000000005 - F1: 0.8565898347407793\n",
      "Threshold:0.38000000000000006 - F1: 0.8629129501399706\n",
      "Threshold:0.39000000000000007 - F1: 0.868926199591246\n",
      "Threshold:0.4000000000000001 - F1: 0.8743222944555005\n",
      "Threshold:0.4100000000000001 - F1: 0.8795463257153483\n",
      "Threshold:0.4200000000000001 - F1: 0.8842590815368498\n",
      "Threshold:0.4300000000000001 - F1: 0.8891689378633886\n",
      "Threshold:0.4400000000000001 - F1: 0.8929264811939516\n",
      "Threshold:0.4500000000000001 - F1: 0.8967264739132388\n",
      "Threshold:0.46000000000000013 - F1: 0.9002619797067279\n",
      "Threshold:0.47000000000000014 - F1: 0.9035653413378164\n",
      "Threshold:0.48000000000000015 - F1: 0.9062124738966897\n",
      "Threshold:0.49000000000000016 - F1: 0.9083074876303644\n",
      "Threshold:0.5000000000000002 - F1: 0.9105297753551862\n",
      "Threshold:0.5100000000000002 - F1: 0.9122337120730979\n",
      "Threshold:0.5200000000000002 - F1: 0.913388375371431\n",
      "Threshold:0.5300000000000002 - F1: 0.9142476209136989\n",
      "Threshold:0.5400000000000003 - F1: 0.9143516216285833\n",
      "Threshold:0.5500000000000003 - F1: 0.9136673155371456\n",
      "Threshold:0.5600000000000003 - F1: 0.9125311418753185\n",
      "Threshold:0.5700000000000003 - F1: 0.9104656881105845\n",
      "Threshold:0.5800000000000003 - F1: 0.9075687918761338\n",
      "Threshold:0.5900000000000003 - F1: 0.9033977183999147\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The best threshold is 0.5400000000000003 with an f1 of 0.9143516216285833\n"
     ]
    }
   ],
   "source": [
    "df, img_threshold, img_f1, img_preds = nearest_neighbor(df, \n",
    "                                                        image_embeddings, \n",
    "                                                        thresholds = np.arange(0.3,0.6,0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_embeddings = embed_titles(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold:0.3 - F1: 0.630776547251398\n",
      "Threshold:0.31 - F1: 0.6352270544040849\n",
      "Threshold:0.32 - F1: 0.6385704191694083\n",
      "Threshold:0.33 - F1: 0.6425737224521486\n",
      "Threshold:0.34 - F1: 0.6461641669803598\n",
      "Threshold:0.35000000000000003 - F1: 0.6496528451842519\n",
      "Threshold:0.36000000000000004 - F1: 0.653089439006744\n",
      "Threshold:0.37000000000000005 - F1: 0.6557794983689451\n",
      "Threshold:0.38000000000000006 - F1: 0.6579680043339512\n",
      "Threshold:0.39000000000000007 - F1: 0.6598584657763932\n",
      "Threshold:0.4000000000000001 - F1: 0.6616317472597671\n",
      "Threshold:0.4100000000000001 - F1: 0.6635153361547791\n",
      "Threshold:0.4200000000000001 - F1: 0.6651819166264529\n",
      "Threshold:0.4300000000000001 - F1: 0.6659392906886799\n",
      "Threshold:0.4400000000000001 - F1: 0.6660580341009082\n",
      "Threshold:0.4500000000000001 - F1: 0.6656979203004432\n",
      "Threshold:0.46000000000000013 - F1: 0.6644144768688384\n",
      "Threshold:0.47000000000000014 - F1: 0.6638981909620011\n",
      "Threshold:0.48000000000000015 - F1: 0.6619719121488122\n",
      "Threshold:0.49000000000000016 - F1: 0.6599119861469871\n",
      "Threshold:0.5000000000000002 - F1: 0.6565343607031406\n",
      "Threshold:0.5100000000000002 - F1: 0.6530940233152942\n",
      "Threshold:0.5200000000000002 - F1: 0.6487327224216957\n",
      "Threshold:0.5300000000000002 - F1: 0.6439416808546439\n",
      "Threshold:0.5400000000000003 - F1: 0.6386301557106345\n",
      "Threshold:0.5500000000000003 - F1: 0.6317908318321429\n",
      "Threshold:0.5600000000000003 - F1: 0.6243050719020539\n",
      "Threshold:0.5700000000000003 - F1: 0.6165415467790359\n",
      "Threshold:0.5800000000000003 - F1: 0.6074322315812006\n",
      "Threshold:0.5900000000000003 - F1: 0.5976332551735322\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The best threshold is 0.4400000000000001 with an f1 of 0.6660580341009082\n"
     ]
    }
   ],
   "source": [
    "df, text_threshold, title_f1, title_preds = nearest_neighbor(df, \n",
    "                                                      title_embeddings, \n",
    "                                                      thresholds = np.arange(0.3,0.6,0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions(row):\n",
    "    '''\n",
    "    Combines image predictions and text predictions (through union)\n",
    "    '''\n",
    "    x = np.union1d(row['pred_img'], row['pred_title'])\n",
    "    return ' '.join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pred_img'] = img_preds\n",
    "df['pred_title'] = title_preds\n",
    "final_pred = df.apply(combine_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArcFace+tfidf f1: 0.8397749437764472\n"
     ]
    }
   ],
   "source": [
    "df['f1'] = util.f1_score(df['matches'], final_pred)\n",
    "score = df['f1'].mean()\n",
    "print(f'ArcFace+tfidf f1: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
